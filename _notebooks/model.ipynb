{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Run of Model\n",
    "\n",
    "In this notebook I run all model functionalities on dummy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data import DummyDataset, DummyDatasetConfig\n",
    "from model import HeirarchicalTransformer, HeirarchicalTransformerConfig\n",
    "\n",
    "from train import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataConfig = DummyDatasetConfig(\n",
    "    n_samples = 1000,\n",
    "    n_nodes = 30,\n",
    "    n_features = 5,\n",
    "    maxlen = 12,\n",
    "    seqlen = 6\n",
    ")\n",
    "wd = DummyDataset(dataConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': (torch.Size([32, 2, 6, 30, 5]), torch.float32), 'node_mask': (torch.Size([32, 2, 6, 30]), torch.int64), 'month_ids': (torch.Size([32, 2, 6]), torch.int64), 'day_ids': (torch.Size([32, 2, 6]), torch.int64), 'hour_ids': (torch.Size([32, 2, 6]), torch.int64)}\n"
     ]
    }
   ],
   "source": [
    "for x in DataLoader(wd, batch_size = 32, shuffle = True):\n",
    "    print({k:(v.size(), v.dtype) for k,v in x.items()})\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConf = HeirarchicalTransformerConfig(\n",
    "    n_embd=dataConfig.n_features * 3,\n",
    "    n_global=12,\n",
    "    maxlen=dataConfig.seqlen,\n",
    "    n_head=3,\n",
    "    n_layer=1,\n",
    "    num_nodes=dataConfig.n_nodes,\n",
    "    num_features=dataConfig.n_features,\n",
    "    location_features=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeirarchicalTransformer(modelConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_params, len([1 for _ in enumerate(model.parameters())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainConf = TrainerConfig(learning_rate = 0.0001, len_data = len(wd), batch_size = 32, weight_decay = 0.1)\n",
    "optim = model.configure_optimizers(train_config = trainConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed93d1ec6624c98ad1fed688812f38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashbonde/Desktop/AI/vv2/optimizer.py:142: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  grad.add_(group['weight_decay'], p.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd45c02e5eb94efd9e509881158ba7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7951aebb103247aa9570bd0066714d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b391961d98646a88be16b8c3dac7da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad08dca52c544c28c566a0db829c5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f4b786f0d547749076164c9f1b48c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-28aaa21b7453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"E{e}; S{i}; L:{loss.item():.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "    pbar = trange((len(wd) // 32) + 1)\n",
    "    for _, x in zip(pbar, DataLoader(wd, batch_size = 32, shuffle = True)):\n",
    "        for i in range(x[\"input\"].size(1)):\n",
    "            in_data = {k:v[:,i,...] for k,v in x.items()}\n",
    "\n",
    "            logits, mems, loss = model(**in_data, edge_matrix = wd.edge_mat, locations = wd.loc_mat, get_loss = True)\n",
    "            pbar.set_description(f\"E{e}; S{i}; L:{loss.item():.3f}\")\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "#             # if you just want to run inference\n",
    "#             logits, mems = model(**in_data, edge_matrix = wd.edge_mat, locations = wd.loc_mat)\n",
    "#             print(logits.size(), len(mems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Mask\n",
    "\n",
    "Below you can see what an attention mask would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = x[\"node_mask\"]\n",
    "mask = torch.zeros(*list(nm.size()), list(nm.size())[-1])\n",
    "for i in range(nm.size(0)):\n",
    "    for j in range(nm.size(1)):\n",
    "        idx = torch.masked_select(\n",
    "            torch.arange(len(nm[i, j])),\n",
    "            nm[i, j] == 0\n",
    "        ).tolist()\n",
    "        if idx:\n",
    "            for k in idx:\n",
    "                mask[i,j,k] = 1e-6\n",
    "                mask[i,j,:,k] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x135d22400>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask[31, 3].tolist())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "\n",
    "Pooling used for node to global embedding is a bit tricky to build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import MaxPool1d, MaxUnpool1d\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChannelPool(MaxPool1d):\n",
    "    def forward(self, input):\n",
    "        n, w, c, h = input.size()\n",
    "        input = input.view(n*w,c,h).permute(0, 2, 1)\n",
    "        pooled =  F.max_pool1d(input, self.kernel_size, self.stride,\n",
    "                        self.padding, self.dilation, self.ceil_mode,\n",
    "                        self.return_indices)\n",
    "        _, _, c = pooled.size()\n",
    "        pooled = pooled.permute(0,2,1)\n",
    "        return pooled.view(n,c,w,h).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3946,  1.8615,  1.4494],\n",
      "          [ 0.0513,  0.3304, -1.4791],\n",
      "          [-1.0684, -0.6103,  1.0675],\n",
      "          [-0.5697,  1.8766, -0.6434],\n",
      "          [-0.3290, -0.8976,  0.0222]],\n",
      "\n",
      "         [[ 0.9958,  2.4677,  0.0356],\n",
      "          [ 0.4293,  0.2765, -0.5181],\n",
      "          [ 2.1385, -0.7111,  0.7266],\n",
      "          [ 0.0982,  0.1368,  0.6872],\n",
      "          [ 0.4947,  0.6898,  0.7542]]],\n",
      "\n",
      "\n",
      "        [[[-0.1334, -0.0656,  1.4724],\n",
      "          [-0.9129, -0.6059,  0.4801],\n",
      "          [-0.0728, -0.9324, -1.6371],\n",
      "          [-0.4414,  0.4389, -0.9090],\n",
      "          [-0.2699, -0.2754,  1.4832]],\n",
      "\n",
      "         [[-0.3492,  0.1914,  0.4929],\n",
      "          [ 1.1793, -1.0775,  0.6775],\n",
      "          [-0.2894,  0.5101,  2.1848],\n",
      "          [-0.0425,  0.3675, -0.6645],\n",
      "          [-2.0476,  0.2867, -1.3523]]]])\n",
      "\n",
      "tensor([[[ 0.0513,  1.8766,  1.4494],\n",
      "         [ 2.1385,  2.4677,  0.7542]],\n",
      "\n",
      "        [[-0.0728,  0.4389,  1.4832],\n",
      "         [ 1.1793,  0.5101,  2.1848]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# this is the node to global pooling\n",
    "p = ChannelPool(5)\n",
    "\n",
    "x = torch.randn(2, 2, 5, 3)\n",
    "print(x)\n",
    "print()\n",
    "y = p(x)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.0513, -1.6148, -0.7327],\n",
      "          [-0.4946, -1.3475,  0.4480],\n",
      "          [ 0.5288, -0.2935, -0.0727],\n",
      "          [ 0.8378,  1.9127, -0.6243],\n",
      "          [ 1.4274, -0.5486, -0.0453]],\n",
      "\n",
      "         [[ 0.4312, -1.5451,  0.8552],\n",
      "          [ 0.3947, -0.4592,  0.7038],\n",
      "          [ 1.0953,  1.2068,  1.6151],\n",
      "          [ 0.8056, -3.2512,  0.7009],\n",
      "          [ 0.0734, -0.6610, -1.4748]]]])\n",
      "tensor([[[-1.1540, -0.4719,  1.3034],\n",
      "         [ 0.4126, -0.7875,  1.5998]]])\n"
     ]
    }
   ],
   "source": [
    "# what about global to node unpooling\n",
    "nodes = torch.randn(1, 2, 5, 3)\n",
    "print(nodes)\n",
    "\n",
    "g = torch.randn(1, 2, 3)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.2053, -2.0867,  0.5707],\n",
       "          [-1.6486, -1.8195,  1.7514],\n",
       "          [-0.6252, -0.7654,  1.2307],\n",
       "          [-0.3162,  1.4408,  0.6791],\n",
       "          [ 0.2734, -1.0205,  1.2581]],\n",
       "\n",
       "         [[ 0.8437, -2.3326,  2.4550],\n",
       "          [ 0.8073, -1.2467,  2.3036],\n",
       "          [ 1.5078,  0.4193,  3.2150],\n",
       "          [ 1.2182, -4.0387,  2.3007],\n",
       "          [ 0.4860, -1.4486,  0.1250]]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes + g.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
